{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "u-vector-dataprocess.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYGV3iRJ0sIc"
      },
      "source": [
        "### Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlVK89uP0tWX"
      },
      "source": [
        "import os, librosa, time, pickle, random, warnings\n",
        "from glob import glob\n",
        "import numpy as np\n",
        " \n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import IPython.display as ipd\n",
        "from IPython.core.display import display, clear_output\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "#%load_ext tensorboard\n",
        " \n",
        "SR = 16_000\n",
        "FRAME = 0.2\n",
        "SECONDS = 10 #5\n",
        "BASE_DIR = './preprocessed_dataset'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KojeMPUZ2ukJ"
      },
      "source": [
        "#### Dataset extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnPsBzVQ06FQ"
      },
      "source": [
        "# Explaining process of extracting librispeech dataset\n",
        "# Link: https://www.openslr.org/12\n",
        "\n",
        "# Extracting tar files into a new folder\n",
        "\n",
        "if not os.path.exists('./LibriSpeech'):\n",
        "    os.makedirs('./LibriSpeech')\n",
        "    os.system(\"tar -zxf './datasets/LibriSpeech/dev-clean.tar.gz'\")\n",
        "    \n",
        "    # If needed you can use these also (used in actual benchmark of the paper)\n",
        "    #os.system(\"tar -zxf './datasets/LibriSpeech/dev-other.tar.gz'\")\n",
        "    #os.system(\"tar -zxf './datasets/LibriSpeech/test-clean.tar.gz'\")\n",
        "    #os.system(\"tar -zxf './datasets/LibriSpeech/test-other.tar.gz'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUCdVgfA23xU"
      },
      "source": [
        "#### Data processig "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slg_FO7u2G37"
      },
      "source": [
        "def process_data(wav_dirs, limit=None, sr=SR, fsize=FRAME, ds=\"LibriSpeech\", \n",
        "                 seconds=SECONDS):\n",
        "    # Length of segments\n",
        "    flens = []\n",
        "    speaker_id = set()\n",
        "    X, person, filetoken, tlen = [], [], [], dict()\n",
        "    frame = int(fsize*sr)\n",
        "    frame_len = sr * seconds\n",
        "    \n",
        "    print(\"Sample rate\", sr)\n",
        "    print(\"Frame size\", frame)\n",
        "    print(\"Frame_len\", frame_len)\n",
        "\n",
        "    # Our code supports TIMIT and Bengali ASR also\n",
        "    if ds == \"TIMIT\":\n",
        "        spkridf = -2\n",
        "    elif ds == \"LibriSpeech\":\n",
        "        spkridf = -3\n",
        "    elif ds != \"ASR\":\n",
        "        print(\"Invalid dataset token\")\n",
        "        return\n",
        "\n",
        "    fileId = 0\n",
        "    for wdir in tqdm(wav_dirs):\n",
        "        if ds[0] ==  \"A\":\n",
        "            spkr = wdir.split('/')[-1]\n",
        "            spkr = spkr.split('.')[0]\n",
        "            if spkr in asr_maps:\n",
        "                spkr = asr_maps[spkr]\n",
        "            else:\n",
        "                continue\n",
        "        else:\n",
        "            spkr = wdir.split('/')[spkridf]\n",
        "\n",
        "        if (limit is not None) and (spkr not in speaker_id):\n",
        "            if len(speaker_id) == limit:\n",
        "                #print(len(speaker_id), limit)\n",
        "                continue\n",
        "            speaker_id.add(spkr)\n",
        "\n",
        "        if spkr not in tlen:\n",
        "            tlen[spkr] = 0\n",
        "        elif tlen[spkr] >= frame_len:\n",
        "            continue\n",
        "\n",
        "        wav, sr = librosa.load(wdir, sr=sr)\n",
        "        sframes = librosa.effects.split(y=wav, frame_length=frame, \n",
        "                                        hop_length=frame//2, top_db=16)\n",
        "\n",
        "        flens.extend(sframes)\n",
        "        \n",
        "        for [st, ed] in sframes: \n",
        "            if ed-st+1 < frame:\n",
        "                continue\n",
        "            idx = 0\n",
        "            while st+(idx+1)*frame < ed:\n",
        "                twav = wav[st+idx*frame:st+(idx+1)*frame]\n",
        "                X.append(twav)\n",
        "                person.append(spkr)\n",
        "                filetoken.append(fileId)\n",
        "                tlen[spkr] += frame\n",
        "                idx += 1\n",
        "\n",
        "                if tlen[spkr] >= frame_len:\n",
        "                    break\n",
        "\n",
        "            if tlen[spkr] >= frame_len:\n",
        "                    break\n",
        "\n",
        "        fileId += 1\n",
        "    \n",
        "    return X, person, filetoken, flens\n",
        "\n",
        "\n",
        "def segment_length(segment_data):\n",
        "    tmp = np.array(segment_data)\n",
        "    tlen = []\n",
        "\n",
        "    for a, b in tmp:\n",
        "        tlen.append(b-a)\n",
        "\n",
        "    tlen = np.array(tlen)\n",
        "    return np.mean(tlen/SR), np.std(tlen/SR), np.median(tlen/SR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-OIRNHz2Jkk"
      },
      "source": [
        "# Cumulative distribution function\n",
        "import scipy\n",
        "import seaborn as sns\n",
        "def CDF(segment_data):\n",
        "    tmp = np.array(segment_data)\n",
        "    tlen = []\n",
        "\n",
        "    for a, b in tmp:\n",
        "        tmp = (b-a+1)\n",
        "        if tmp < FRAME:\n",
        "            continue\n",
        "        tlen.append(tmp/SR)\n",
        "\n",
        "\n",
        "    tlen = sorted(tlen)\n",
        "    print(tlen[:10])\n",
        "    norm_cdf = scipy.stats.norm.cdf(tlen) # calculate the cdf - also discrete\n",
        "\n",
        "    # plot the cdf\n",
        "    #sns.lineplot(x=tlen, y=norm_cdf)\n",
        "    #plt.show()\n",
        "    plt.plot(tlen, norm_cdf)\n",
        "    plt.xlim([0, 2])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.grid(), plt.minorticks_on();\n",
        "    plt.grid(b=True, which='minor', linestyle='-', alpha=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFelSaa_2ZlO"
      },
      "source": [
        "X, py, fy, segs = process_data(asr_wav_dirs, fsize=FRAME, ds=\"LibriSpeech\", seconds=SECONDS)\n",
        "print(segment_length(segs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwAHyEEL2pHV"
      },
      "source": [
        "CDF(segs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euZhXbEi28Us"
      },
      "source": [
        "#### Saving data into pickle file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvNr4Q_R2p_K"
      },
      "source": [
        "X, py, fy  = process_data(libri_wav_dirs, fsize=FRAME, ds=\"LibriSpeech\", seconds=SECONDS)\n",
        "\n",
        "with open(os.path.join(BASE_DIR, f'LIBRI_X_16000_{SECONDS}_{FRAME}.pkl'), 'wb') as f:\n",
        "    pickle.dump(X, f)\n",
        "with open(os.path.join(BASE_DIR, f'LIBRI_y_16000_{SECONDS}_{FRAME}.pkl'), 'wb') as f:\n",
        "    pickle.dump(py, f)\n",
        "with open(os.path.join(BASE_DIR, f'LIBRI_fy_16000_{SECONDS}_{FRAME}.pkl'), 'wb') as f:\n",
        "    pickle.dump(fy, f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}